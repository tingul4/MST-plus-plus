{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fafa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets/io.py\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Mapping, Optional, Sequence, Tuple\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "__all__ = [\n",
    "    \"list_by_ext\",\n",
    "    \"build_stem_map\",\n",
    "    \"intersect_modalities\",\n",
    "    \"read_h5_cube\",\n",
    "    \"read_rgb_image\",\n",
    "]\n",
    "\n",
    "\n",
    "def list_by_ext(root: Path, exts: Sequence[str]) -> List[Path]:\n",
    "    exts = [e.lower() for e in exts]\n",
    "    files = [p for p in root.iterdir() if p.is_file() and p.suffix.lower() in exts]\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "\n",
    "def build_stem_map(root: Path, exts: Sequence[str]) -> Dict[str, Path]:\n",
    "    \"\"\"\n",
    "    Build {stem: path} for a folder, preferring earlier extensions in `exts` on collisions.\n",
    "    \"\"\"\n",
    "    root = Path(root)\n",
    "    exts = [e.lower() for e in exts]\n",
    "    by_stem: Dict[str, Path] = {}\n",
    "    for p in root.iterdir():\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        ext = p.suffix.lower()\n",
    "        if ext not in exts:\n",
    "            continue\n",
    "        stem = p.stem\n",
    "        if stem not in by_stem:\n",
    "            by_stem[stem] = p\n",
    "        else:\n",
    "            # prefer higher priority ext (smaller index)\n",
    "            old = by_stem[stem]\n",
    "            if exts.index(ext) < exts.index(old.suffix.lower()):\n",
    "                by_stem[stem] = p\n",
    "    return by_stem\n",
    "\n",
    "\n",
    "def intersect_modalities(maps: Mapping[str, Dict[str, Path]]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Given a dict of {modality: {stem: path}}, return stems present in ALL modalities.\n",
    "    \"\"\"\n",
    "    it = iter(maps.values())\n",
    "    common = set(next(it).keys())\n",
    "    for d in it:\n",
    "        common &= set(d.keys())\n",
    "    stems = sorted(common)\n",
    "    return stems\n",
    "\n",
    "\n",
    "def read_h5_cube(path: Path, dataset_name: str = \"cube\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Read HDF5 cube as HxWxC float32. Accepts CxHxW as well and transposes.\n",
    "    \"\"\"\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        if dataset_name not in f:\n",
    "            raise KeyError(f\"'{dataset_name}' not in {path}. Keys: {list(f.keys())}\")\n",
    "        arr = np.array(f[dataset_name], dtype=np.float32)\n",
    "    # accept common layouts\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D cube, got {arr.shape} in {path}\")\n",
    "    # If data is C,H,W -> transpose to H,W,C\n",
    "    if arr.shape[0] in (31, 61, 62, 448) and arr.shape[0] < arr.shape[-1]:\n",
    "        arr = np.transpose(arr, (1, 2, 0))\n",
    "    return arr  # H,W,C\n",
    "\n",
    "\n",
    "def read_rgb_image(path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Read RGB as float32 HxWx3 in [0,1] without per-image min-max normalization.\n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    arr = np.asarray(img, dtype=np.float32) / 255.0\n",
    "    return arr\n",
    "\n",
    "\n",
    "def read_mosaic(path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Read a mosaic saved as .npy.\n",
    "    Returns HxWx1 float32 array in [0,1].\n",
    "    \"\"\"\n",
    "    arr = np.load(path).astype(np.float32)\n",
    "\n",
    "    # If it's 2D, add channel dim -> (H,W,1)\n",
    "    if arr.ndim == 2:\n",
    "        arr = arr[..., None]\n",
    "\n",
    "    # Normalize if values look like 8-bit integers\n",
    "    if arr.max() > 1.0:\n",
    "        arr = arr / 255.0\n",
    "\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c12d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets/pairing.py\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Sequence\n",
    "\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModalitySpec:\n",
    "    root: Path\n",
    "    exts: Sequence[str]\n",
    "\n",
    "\n",
    "def build_index(\n",
    "    specs: Dict[str, ModalitySpec],\n",
    "    id_list_path: Optional[Path] = None,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Build a list of sample IDs (stems) present in ALL modalities.\n",
    "    Optionally constrain by an id list file (one stem per line).\n",
    "    \"\"\"\n",
    "    maps = {name: build_stem_map(spec.root, spec.exts) for name, spec in specs.items()}\n",
    "    stems = intersect_modalities(maps)\n",
    "\n",
    "    if id_list_path is not None:\n",
    "        keep = set(\n",
    "            [\n",
    "                ln.strip()\n",
    "                for ln in Path(id_list_path).read_text().splitlines()\n",
    "                if ln.strip()\n",
    "            ]\n",
    "        )\n",
    "        stems = [s for s in stems if s in keep]\n",
    "\n",
    "    if not stems:\n",
    "        raise RuntimeError(\"No common stems across modalities (after filtering).\")\n",
    "    return stems, maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9c62c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielchen/miniconda3/envs/mstpp/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# datasets/base.py\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "__all__ = [\"HSIDataset\", \"JointTransform\"]\n",
    "\n",
    "\n",
    "class HSIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Thin Dataset base that mirrors torchvision semantics:\n",
    "    - Optionally accepts a 'transforms' callable that can operate jointly\n",
    "      on input(s) and target(s).\n",
    "    - Or separate 'transform' and 'target_transform'.\n",
    "    \"\"\"\n",
    "\n",
    "    _repr_indent = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        transforms: Optional[Callable] = None,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        self.root = root\n",
    "        if transforms is not None and (\n",
    "            transform is not None or target_transform is not None\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Pass either `transforms` or (`transform` and/or `target_transform`), not both.\"\n",
    "            )\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.transforms = transforms\n",
    "\n",
    "    # subclasses implement __getitem__, __len__\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        head = \"Dataset \" + self.__class__.__name__\n",
    "        body = [f\"Number of datapoints: {len(self)}\"]\n",
    "        if self.root is not None:\n",
    "            body.append(f\"Root location: {self.root}\")\n",
    "        if hasattr(self, \"transforms\") and self.transforms is not None:\n",
    "            body += [repr(self.transforms)]\n",
    "        lines = [head] + [\" \" * self._repr_indent + line for line in body]\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "class JointTransform:\n",
    "    \"\"\"\n",
    "    Helper to apply a single callable to (inputs, target) jointly.\n",
    "    Your callable should take and return a dict of arrays/tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fn: Callable[[Dict[str, Any]], Dict[str, Any]]):\n",
    "        self.fn = fn\n",
    "\n",
    "    def __call__(self, batch: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        return self.fn(batch)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.fn})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41deac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets/rgb_hsi.py\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "__all__ = [\"HyperObjectDataset\"]\n",
    "\n",
    "\n",
    "class HyperObjectDataset(HSIDataset):\n",
    "    \"\"\"\n",
    "    Returns a dict:\n",
    "      {\n",
    "        \"input\": \"mosaic\" (1,H,W) float32 or \"rgb_2\"  (3,H,W) float32,\n",
    "        \"output\":  \"cube\"   (C,H,W) float32,\n",
    "        \"id\":     str\n",
    "      }\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        track: int,\n",
    "        data_root: str,\n",
    "        train: bool = True,\n",
    "        transforms: Optional[Callable] = None,\n",
    "        submission: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(root=data_root, transforms=transforms)\n",
    "        self.track = track\n",
    "\n",
    "        if track == 1:\n",
    "            if submission:\n",
    "                mosaic_path = ModalitySpec(\n",
    "                    root=Path(f\"{data_root}/test-private/mosaic\"), exts=(\".npy\",)\n",
    "                )\n",
    "            else:\n",
    "                mosaic_path = ModalitySpec(\n",
    "                    root=Path(\n",
    "                        f\"{data_root}/{'train' if train else 'test-public'}/mosaic\"\n",
    "                    ),\n",
    "                    exts=(\".npy\",),\n",
    "                )\n",
    "                hsi_61_path = ModalitySpec(\n",
    "                    root=Path(\n",
    "                        f\"{data_root}/{'train' if train else 'test-public'}/hsi_61\"\n",
    "                    ),\n",
    "                    exts=(\".h5\",),\n",
    "                )\n",
    "            (self.ids, self._maps) = build_index(\n",
    "                {\n",
    "                    \"mosaic\": mosaic_path,\n",
    "                    \"hsi\": hsi_61_path,\n",
    "                }\n",
    "            )\n",
    "        elif track == 2:\n",
    "            specs = {}\n",
    "            if submission:\n",
    "                rgb_2_path = ModalitySpec(\n",
    "                    root=Path(f\"{data_root}/test-private/rgb_2\"), exts=(\".png\", \".jpg\")\n",
    "                )\n",
    "                specs[\"rgb_2\"] = rgb_2_path\n",
    "            else:\n",
    "                rgb_2_path = ModalitySpec(\n",
    "                    root=Path(\n",
    "                        f\"{data_root}/{'train' if train else 'test-public'}/rgb_2\"\n",
    "                    ),\n",
    "                    exts=(\".png\", \".jpg\"),\n",
    "                )\n",
    "                hsi_61_path = ModalitySpec(\n",
    "                    root=Path(\n",
    "                        f\"{data_root}/{'train' if train else 'test-public'}/hsi_61\"\n",
    "                    ),\n",
    "                    exts=(\".h5\",),\n",
    "                )\n",
    "                specs[\"rgb_2\"] = rgb_2_path\n",
    "                specs[\"hsi\"] = hsi_61_path\n",
    "            (self.ids, self._maps) = build_index(specs)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.ids)\n",
    "\n",
    "    def _load_(self, stem: str):\n",
    "        if \"hsi\" in self._maps:\n",
    "            p_hsi = self._maps[\"hsi\"][stem]\n",
    "            cube = read_h5_cube(p_hsi, \"cube\")  # (H,W,C)\n",
    "            cube_t = torch.from_numpy(np.transpose(cube, (2, 0, 1)))  # C,H,W\n",
    "        else:\n",
    "            cube_t = torch.empty(0)  # Placeholder\n",
    "\n",
    "        if self.track == 1:\n",
    "            p_mosaic = self._maps[\"mosaic\"][stem]\n",
    "            mosaic = read_mosaic(p_mosaic)  # (H,W,1) float32 [0,1]\n",
    "            mosaic_t = torch.from_numpy(np.transpose(mosaic, (2, 0, 1)))  # 1,H,W\n",
    "            return mosaic_t, cube_t\n",
    "        elif self.track == 2:\n",
    "            p_rgb_2 = self._maps[\"rgb_2\"][stem]\n",
    "            rgb_2 = read_rgb_image(p_rgb_2)  # (H,W,3) float32 [0,1]\n",
    "            rgb_2_t = torch.from_numpy(np.transpose(rgb_2, (2, 0, 1)))  # C,H,W\n",
    "            return rgb_2_t, cube_t\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        stem = self.ids[idx]\n",
    "        input_data, output_data = self._load_(stem)\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transforms is not None:\n",
    "            # joint transform expects dict\n",
    "            out = self.transforms(\n",
    "                {\"input_data\": input_data, \"output_data\": output_data, \"id\": stem}\n",
    "            )\n",
    "            input_data, output_data = out[\"input_data\"], out[\"output_data\"]\n",
    "\n",
    "        return {\n",
    "            \"input\": input_data,  # either mosaic or rgb_2 depending on track\n",
    "            \"output\": output_data,  # hsi (61 bands)\n",
    "            \"id\": stem,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca76986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Individual prediction files will be saved in: 'submission/files'\n",
      "Filtering dataset to 4 specific IDs for testing.\n",
      "DataLoader created for 4 samples.\n",
      "Loading checkpoint from: /ssd7/ICASSP_2026_Hyper-Object_Challenge/track2/MST-plus-plus/exp/mst_plus_plus_sr2x/2025_10_08_16_56_56/MSTPP_3_35.249081.pth\n",
      "Model 'MST_Plus_Plus' loaded and set to HR evaluation mode.\n",
      "\n",
      "Generating predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 4/4 [01:00<00:00, 15.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All 4 predictions saved.\n",
      "\n",
      "Creating submission.csv...\n",
      "submission.csv created with 4 entries.\n",
      "Creating submission zip file at: 'submission/zip/submission_202510082142.zip'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zipping .npz files: 100%|██████████| 4/4 [00:24<00:00,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Submission process complete!\n",
      "File to submit to Kaggle: submission/zip/submission_202510082142.zip\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# from baselines import mstpp_up\n",
    "# from SPECAT import SPECAT\n",
    "from train_code.architecture import MST_Plus_Plus\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "TARGET_IDS = {\n",
    "    \"Category-1_a_0007\",\n",
    "    \"Category-2_a_0009\",\n",
    "    \"Category-3_a_0035\",\n",
    "    \"Category-4_a_0018\",\n",
    "}\n",
    "\n",
    "data_dir = \"/ssd7/ICASSP_2026_Hyper-Object_Challenge/track2/dataset\"\n",
    "model_path = \"/ssd7/ICASSP_2026_Hyper-Object_Challenge/track2/MST-plus-plus/exp/mst_plus_plus_sr2x/2025_10_08_16_56_56/MSTPP_3_35.249081.pth\"\n",
    "submission_files_dir = \"submission/files\"\n",
    "submission_zip_path = f\"submission/zip/submission_{datetime.now().strftime('%Y%m%d%H%M')}.zip\"\n",
    "\n",
    "# MODEL_NAME = 'MST_Plus_Plus_Up'\n",
    "# MODEL_NAME = \"SPECAT\"\n",
    "MODEL_NAME = \"MST_Plus_Plus\"\n",
    "UPSCALE_FACTOR = 2\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "def create_submission():\n",
    "    \"\"\"\n",
    "    Generates predictions and packages them for Kaggle submission.\n",
    "    \"\"\"\n",
    "    processed_ids = []\n",
    "    os.makedirs(submission_files_dir, exist_ok=True)\n",
    "    print(f\"Individual prediction files will be saved in: '{submission_files_dir}'\")\n",
    "\n",
    "    full_ds_test = HyperObjectDataset(\n",
    "        data_root=f\"{data_dir}\",\n",
    "        track=2,\n",
    "        train=False,\n",
    "        submission=True,\n",
    "    )\n",
    "\n",
    "    if TARGET_IDS is not None:\n",
    "        print(f\"Filtering dataset to {len(TARGET_IDS)} specific IDs for testing.\")\n",
    "        desired_indices = [\n",
    "            i for i, sample in enumerate(full_ds_test) if sample[\"id\"] in TARGET_IDS\n",
    "        ]\n",
    "        submission_dataset = Subset(full_ds_test, desired_indices)\n",
    "    else:\n",
    "        print(\"Processing the full test dataset for final submission.\")\n",
    "        submission_dataset = full_ds_test\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=submission_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        pin_memory=True if device == \"cuda\" else False,\n",
    "    )\n",
    "    print(f\"DataLoader created for {len(submission_dataset)} samples.\")\n",
    "\n",
    "    print(f\"Loading checkpoint from: {model_path}\")\n",
    "    # model = SPECAT(\n",
    "    #     in_channels=3,\n",
    "    #     dim=61,\n",
    "    #     stage=1,\n",
    "    #     num_blocks=[2, 1],\n",
    "    #     attention_type=opt.attention_type,\n",
    "    # ).cuda()\n",
    "    model = MST_Plus_Plus(in_channels=3, out_channels=61, n_feat=31, stage=3, upscale_factor=UPSCALE_FACTOR)#.cuda()\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict({k.replace('module.', ''): v for k, v in checkpoint['state_dict'].items()}, strict=True)\n",
    "    # model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model.return_hr = True\n",
    "    print(f\"Model '{MODEL_NAME}' loaded and set to HR evaluation mode.\")\n",
    "\n",
    "    print(\"\\nGenerating predictions...\")\n",
    "    for data in tqdm(test_loader, desc=\"Generating predictions\"):\n",
    "        x = data[\"input\"].float().to(device)\n",
    "        sample_id = data[\"id\"][0]\n",
    "        processed_ids.append(sample_id)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_hr_tensor = model(x)\n",
    "\n",
    "        pred_np = pred_hr_tensor.squeeze(0).cpu().numpy()\n",
    "        pred_hwc = np.transpose(pred_np, (1, 2, 0))\n",
    "\n",
    "        pred_hwc_clipped = np.clip(pred_hwc, 0.0, 1.0)\n",
    "\n",
    "        output_npz_path = os.path.join(submission_files_dir, f\"{sample_id}.npz\")\n",
    "        np.savez_compressed(output_npz_path, cube=pred_hwc_clipped)\n",
    "\n",
    "    print(f\"\\nAll {len(submission_dataset)} predictions saved.\")\n",
    "\n",
    "    print(\"\\nCreating submission.csv...\")\n",
    "    submission_df = pd.DataFrame({\"id\": processed_ids, \"prediction\": 0})\n",
    "    csv_path = os.path.join(submission_files_dir, \"submission.csv\")\n",
    "    submission_df.to_csv(csv_path, index=False)\n",
    "    print(f\"submission.csv created with {len(submission_df)} entries.\")\n",
    "\n",
    "    print(f\"Creating submission zip file at: '{submission_zip_path}'\")\n",
    "    with zipfile.ZipFile(submission_zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.write(csv_path, arcname=\"submission.csv\")\n",
    "\n",
    "        files_to_zip = [f\"{sid}.npz\" for sid in processed_ids]\n",
    "        for filename in tqdm(files_to_zip, desc=\"Zipping .npz files\"):\n",
    "            file_path = os.path.join(submission_files_dir, filename)\n",
    "            if os.path.exists(file_path):\n",
    "                zf.write(file_path, arcname=filename)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Submission process complete!\")\n",
    "    print(f\"File to submit to Kaggle: {submission_zip_path}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_submission()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db4e8601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 828M/828M [00:31<00:00, 27.7MB/s]\n",
      "Successfully submitted to 2026 ICASSP Hyper-Object Challenge: Track 2"
     ]
    }
   ],
   "source": [
    "message = \"MST++ with MRAE in 3 epochs\"\n",
    "!kaggle competitions submit -c \"2026-icassp-hyper-object-challenge-track-2\" -f \"{submission_zip_path}\" -m \"{message}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mstpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
